<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>NFL Performance Research &amp; Prediction | Eric Matthew Rupinski </title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="In-Depth Research of Performance Factors in the NFL With a Focus in Predicting Team Player Performance Outcomes">
    <meta name="generator" content="Hugo 0.115.4">
    
    
    
    
      <meta name="robots" content="noindex, nofollow">
    

    
<link rel="stylesheet" href="https://emr89.github.io/ananke/css/main.min.css" >



    
    
    
      

    

    
    
    <meta property="og:title" content="NFL Performance Research &amp; Prediction" />
<meta property="og:description" content="In-Depth Research of Performance Factors in the NFL With a Focus in Predicting Team Player Performance Outcomes" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://emr89.github.io/post/nfl-performance/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2020-08-09T10:58:08-04:00" />
<meta property="article:modified_time" content="2020-08-09T10:58:08-04:00" />
<meta itemprop="name" content="NFL Performance Research &amp; Prediction">
<meta itemprop="description" content="In-Depth Research of Performance Factors in the NFL With a Focus in Predicting Team Player Performance Outcomes"><meta itemprop="datePublished" content="2020-08-09T10:58:08-04:00" />
<meta itemprop="dateModified" content="2020-08-09T10:58:08-04:00" />
<meta itemprop="wordCount" content="17839">
<meta itemprop="keywords" content="Scene," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="NFL Performance Research &amp; Prediction"/>
<meta name="twitter:description" content="In-Depth Research of Performance Factors in the NFL With a Focus in Predicting Team Player Performance Outcomes"/>

	
  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  
  <header class="cover bg-top" style="background-image: url('https://emr89.github.io/images/NFL22.jpeg');">
    <div class="bg-black-60">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="https://emr89.github.io/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        Eric Matthew Rupinski 
      
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://emr89.github.io/about/" title="About page">
              About
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://emr89.github.io/contact/" title="Contact page">
              Contact
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://emr89.github.io/post/" title="Projects page">
              Projects
            </a>
          </li>
          
        </ul>
      
      
<div class="ananke-socials">
  
</div>

    </div>
  </div>
</nav>

      <div class="tc-l pv6 ph3 ph4-ns">
        
          <div class="f2 f1-l fw2 white-90 mb0 lh-title">NFL Performance Research &amp; Prediction</div>
          
            <div class="fw1 f5 f3-l white-80 measure-wide-l center lh-copy mt3 mb4">
              In-Depth Research of Performance Factors in the NFL With a Focus in Predicting Team Player Performance Outcomes
            </div>
          
        
      </div>
    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked">
          
        PROJECTS
      </aside>
      










  <div id="sharing" class="mt3 ananke-socials">
    
  </div>


      <h1 class="f1 athelas mt3 mb1">NFL Performance Research &amp; Prediction</h1>
      
      
      
      <time class="f6 mv4 dib tracked" datetime="2020-08-09T10:58:08-04:00">August 9, 2020</time>
      

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><h4 id="link-to-github-httpsgithubcomemr89nfl-performance-research">Link to Github: <a href="https://github.com/Emr89/NFL-Performance-Research">https://github.com/Emr89/NFL-Performance-Research</a></h4>
<h2 id="description-and-layout-of-project">Description and Layout of Project:</h2>
<h4 id="comprehensive-project-goal">Comprehensive Project Goal:</h4>
<p>The prime objective of this project is to supply the Lions with an alternative means of analyzing and predicting team performance, which can be utilized to create strategic improvements throughout the season. The most effective method to achieve this alternate method was to develop the most advantageous statistical models for analysis and prediction. A notable benefit to implementing advanced statistical methods is the ability to measure, with a relatively high degree of accuracy, the probability of success for potential game strategies, without having to test them in live game scenarios beforehand. Though it is crucial to note that scientifically conducted examination of game strategies in practice and non-critical scenarios in live games, will only strengthen the degree of accuracy overall.</p>
<p>The process of constructing advantageous statistical models can be divided into three essential themes: Meaningful Measurements, Precise Factor Analysis, and Intricate Prediction Modeling, which are implemented in all elements of the project. Essentially, the fundamental notions implemented were the notions of: creating unique datasets to explore untested factor relationships, defining those factor relationships with accurate scope to prevent misapplication of significant factor relationships, and delicately crafting accurate methods of prediction around those significant factor relationships with advanced statistical modeling techniques to maximize the effectiveness of the resulting predictions. Due to this, I have created three conceptually focused areas of study inside the comprehensive project: Comparative Team Analysis, Position Performance Extrapolation, and Matchup Prediction and Corrective Analysis.</p>
<h6 id="note-the-conceptual-areas-of-focus-section-will-use-the-rams-application-as-the-example-but-all-application-examples-have-endured-a-nearly-identical">NOTE: The “Conceptual Areas of Focus” section will use the Rams application as the example, but all application examples have endured a nearly identical</h6>
<h3 id="conceptual-areas-of-focus">Conceptual Areas of Focus:</h3>
<h4 id="1-comparative-team-analysis-cta-is-the-measure-of-relative-ability-and-performance-for-one-desired-team-compared-to-the-rest-of-the-league">1. Comparative Team Analysis (CTA): is the measure of relative ability and performance for one desired team compared to the rest of the league.</h4>
<p>Various datasets were divided into subsets by team, and relative performance data was measured and analyzed. This relative performance data was either measured by a single positional Z score, or a relative T distribution, or a test of Chi Squared significance. The Z score positional data included performance measures that had only one value, which often was a measure of seasonal performance, or a measure of full team performance. These comprehensive Z score value are a measure of performance relative to the other teams in the league. The Z score values of the LA Rams and the Arizona Cardinals were found to measure relative ability compared to the rest of the teams in the league. The T distribution data included performance measures that had several values of performance, which often was weekly position and player performance. The T distributions essentially measured the mean value of a performance statistic along with its consistency. The T distributions for the LA Rams and the Arizona Cardinals were found, and then compared to the distributions for the NFL in its entirety. Finally, the Chi Squared data measured if certain “categorical” features had any significant influence on performance. Mainly, the side of the field (left, middle, or right) and depth of the field (-10 yards to Line of Scrimmage, Line of Scrimmage to 10 yards, 10-20 yards, and 20-30 yards), were measured against several performance statistics for all positions to determine if the location on the field had any significant impact on the level of performance. These Chi Squared tests were calculated for performance statistics for the LA Rams and Arizona Cardinals.  Altogether, the comparative performance scores provide an in-depth measure of relative ability for both the LA Rams and the Arizona Cardinals for their match-up, which serves as a foundation for the theoretical analysis utilized in the MPCA section. Though this subset uses relatively simple statistical methods, the output of these methods are the building blocks for the advanced techniques of estimation and extrapolation. Comparative Team Analysis is crucial for the foundations of the Matchup Prediction and Corrective Analysis subset, as the relative performance serves as a baseline for understanding matchup scenarios and creating accurate corrective analysis.</p>
<h4 id="2position-performance-extrapolation-ppe-is-identifying-and-understanding-specific-factor-relationships-and-their-impact-on-predicting-performance-for-several-positional-units-on-the-team">2.	Position Performance Extrapolation (PPE): is identifying and understanding specific factor relationships and their impact on predicting performance for several positional units on the team.</h4>
<p>Various datasets, that I have constructed from a combination of sources, were applied to a handful of well-known statistical modeling methods, to see which method created was the most consistently accurate model. These methods are the following: Linear Based Regressions (simple linear regression, multiple linear regression, and a GLMULTI process of multiple linear regression), Poisson Regression (when applicable), and Random Forest Modeling. For the Linear Based Regressions, there were several methods of selecting variable subsets, such as subset optimization with “regsubsets”, and exhaustive model comparisons with “GLMULTI”. Several combinations of variables are tested for each desired performance statistic. Additionally, several variations of those individual models exist based on the amount of interactions allowed in the model. For Poisson Regression, models are created only for variables that could reasonably be Poisson distributed. Two combinations of variables were created, and interaction models for both combinations were also created. Finally, for Random Forest models, most of the data was used to train the Random Forest. These Random Forest models were then tested with data that was not already in use in the training process. The various datasets all had variables that were modelled in all the following ways above. Finally, all models were tested with actual data that was not used to create said models. Once all the predictions were made, and the variation from the actual values were measured, the methods of modelling were analyzed to find the most effective method for prediction. The statistical methods in this subset are far more advanced and delicate than any other subset. Simply stated, the prediction of performance variables relies heavily on the mathematical relationships between several descriptive factors. This subset focuses deeply on a research-oriented investigation of several statistical models and methods for prediction. This investigation is conducted in a trial by error manner, where a plethora of statistical models are created using varying statistical methods, that all operate based on various assumptions, to best predict the performance variables. The best statistical models are the ones that can be generalized for extrapolation, while still being mostly accurate. Those statistical models that were considered the best are then analyzed to understand the relationships between the factors that cause the output of the performance variable to be what it is. These factor relationships can be utilized to improve performance by a form of variable manipulation, which when applied directly to football, emphasizes significant structural areas of team/player performance through coaching and game planning.</p>
<h4 id="3matchup-prediction-and-corrective-analysis-mpca-is-the-application-of-the-output-and-analysis-for-both-the-position-performance-extrapolation-and-the-comparative-team-analysis-subsets-essentially-this-is-a-case-study">3.	Matchup Prediction and Corrective Analysis (MPCA): is the application of the output and analysis for both the Position Performance Extrapolation and the Comparative Team Analysis subsets. Essentially, this is a case study.</h4>
<p>The CTA and PPE sections were applied to a match-up between the LA Rams and the Arizona Cardinals at the end of the 2019 season on December 28th, 2019. The data used to create the prediction models did NOT include any data from the outcome of that game, so the acquired predictions were extrapolations. This section takes one comprehensive dataset, that I created from weekly match up performance variables, and applies the processes I applied in the CTA and PPE section, to create predictions for outcome and performance for this match-up. This application is utilized so that matchups between these two teams can be predicted and analyzed to create a strategy for a desired match-up outcome. Essentially, this subset is the culmination of the research analysis, such that it can be utilized for situational understanding and manipulation. The statistical methods in this subset are the same methods from the first two subsets, as this subset is a case study application of the research. The resulting product of this application is the essential portion of this subset, as the focus of this subset is to connect the statistical research methods to game performance and planning by converting the output of such methods into a cohesive flow of analysis that can be easily recognized and applied directly to situationally specific strategies and game plans.</p>
<h2 id="application-of-methods">Application of Methods:</h2>
<h5 id="note-extra-models-were-created-in-each-subset-to-test-the-validity-of-the-assumptions-of-the-techniques-implemented-this-was-partially-for-my-own-reference-but-mainly-for-research-purposes">Note: Extra models were created in each subset to test the validity of the assumptions of the techniques implemented. This was partially for my own reference, but mainly for research purposes.</h5>
<h4 id="details-of-code-steps">Details of Code steps:</h4>
<h5 id="cta">CTA:</h5>
<h5 id="part-one-basic-descriptive-statistics">Part One: Basic Descriptive Statistics</h5>
<p>•	Loaded in Datasets.</p>
<p>•	Created subsets for Rams and Cardinals from those datasets.</p>
<p>•	Found Z scores for single points positions for subsets.</p>
<p>•	Used T tests to determine if subsets have their own distribution and if so, what their mean and standard deviation is.</p>
<p>•	Plotted variables in own dataset next to each other.</p>
<p>•	Tested Chi Square to determine if area of field impacted performance. These Chi Squared focus on interaction of side and depth of field.</p>
<h5 id="ppe">PPE:</h5>
<h5 id="part-two-subsearch-optimization-search">Part Two: Subsearch optimization search</h5>
<p>•	Loaded in all datasets</p>
<p>•	Created normalized datasets</p>
<p>•	Created hypothetical prediction models for all variables based on:</p>
<p><code>o	Rest of variables in dataset.</code></p>
<p><code>o	Specific selected variables.</code></p>
<p><code>o	NORMALIZED rest of variables in dataset.</code></p>
<p><code>o	NORMALIZED specific selected variables.</code></p>
<p>•	Used a step VIF function to get rid of the collinearity from each model.</p>
<p>•	Inserted step VIF models into a regsubsets to find model formula with best adjusted R^2 for each model.</p>
<p>•	Extracted the formula of the best subset for each model.</p>
<h5 id="part-three-linear-based-models">Part Three: Linear Based Models</h5>
<p>•	Loaded in all datasets.</p>
<p>•	Created normalized datasets.</p>
<p>•	Renamed some variable names for ease.</p>
<p>•	Created First order Linear model for all variables in all datasets (Normalized and Regular).</p>
<p>•	Created Second order Linear model for all variables in all datasets (Normalized and Regular).</p>
<p>•	Created Highest order Linear model for all variables in all datasets (Normalized and Regular).</p>
<p>•	Used step function on Second order model to find best combination of interactions.</p>
<p>•	Used step function on Highest order model to find best combination of interactions.</p>
<p>•	Used plugged in values to assess the accuracy of the model.</p>
<h5 id="part-three-a-datasets-added-after-completion-of-steps-one-three">Part Three A: Datasets Added After Completion of Steps One-Three</h5>
<p>•	Repeated of all steps from (Parts One – Three) for two new datasets.</p>
<h5 id="part-four-poisson-based-models">Part Four: Poisson Based Models</h5>
<p>•	Loaded in all datasets.</p>
<p>•	Created normalized datasets.</p>
<p>•	Created Poisson models for variables that possibly could have been Poisson distributed.</p>
<p>•	Used step function for those models.</p>
<p>•	Created Poisson models with interactions.</p>
<p>•	Used step function on interaction models.</p>
<p>•	Created new models from stepVIF function.</p>
<p>•	Predicted all Poisson models.</p>
<h5 id="part-five-glmulti-models">Part Five: GLMULTI Models</h5>
<p>•	Loaded in all datasets.</p>
<p>•	Created normalized datasets.</p>
<p>•	Used GLMULTI function on various situational prediction models to determine the model with the lowest AIC out of all the models to find the best model.</p>
<h5 id="part-six-random-forest-models">Part Six: Random Forest Models</h5>
<p>•	Loaded in all datasets.</p>
<p>•	Created normalized datasets.</p>
<p>•	Constructed train data sets for Random Forest models.</p>
<p>•	Created Random Forest models.</p>
<p>•	Created predictions of Random Forest model to measure accuracy.</p>
<p>•	Plotted Tree from Random Forest models.</p>
<h5 id="part-seven-team-specific-weekly-team-performance-models">Part Seven: Team Specific “WEEKLY TEAM PERFORMANCE” Models</h5>
<p>•	Loaded in all datasets.</p>
<p>•	Defined data used for prediction.</p>
<p>•	Defined GLMULTI models.</p>
<p>•	Set up train data sets for Random Forest models.</p>
<p>•	Created Random Forest models.</p>
<p>•	Created predictions for all models.</p>
<h5 id="part-eight-team-specific-model-analysis">Part Eight: Team Specific Model Analysis</h5>
<p>•	Combined All steps for Parts two through six for team specific analysis and models.</p>
<h5 id="mpca">MPCA:</h5>
<h5 id="part-nine-prediction-of-week-based-matchup-performance">Part Nine: Prediction of Week Based Matchup Performance</h5>
<p>•	Loaded in specialized combination dataset.</p>
<p>•	Created normalized datasets.</p>
<p>•	Created baseline linear models for all variables.</p>
<p>•	Used step VIF to get rid of collinearity.</p>
<p>•	Used Regsubsets to find the best subset of variables, one subset with six variables, one subset with the however many needed for highest ADJ R^2.</p>
<p>•	Created Random Forest Models for new dataset.</p>
<p>•	Created First order Linear model for all variables in all datasets (Normalized and Regular).</p>
<p>•	Created Second order Linear model for all variables in all datasets (Normalized and Regular).</p>
<p>•	Created Highest order Linear model for all variables in all datasets (Normalized and Regular).</p>
<p>•	Used step function on Second order model to find best combination of interactions.</p>
<p>•	Used step function on Highest order model to find best combination of interactions.</p>
<p>•	Used GLMULTI function to find best model with lowest AIC.</p>
<p>•	Predictions for all models to see accuracy of models.</p>
<p>Conclusions:
CTA Conclusion:
The process of creating unique datasets was found to be useful, as several factor relationships between variables, merged appropriately from various datasets, resulted in being statistically significant. These findings implicitly indicate that significant influential interactions were missing from known model of prediction, as those published models did not include any evidence of implementation of factors included in this study.
The culmination of the Z, T, and Chi Squared scores provide a multi-dimensional comparison between the LA Rams and the Arizona Cardinals, which are utilized for the match-up between both teams in the “MPCA: Match Up Analysis and Game Plan” section. All specific Z, T, and Chi Square scores can be provided upon request.</p>
<p>PPE Conclusion:
After analyzing the entire collection of models throughout this section, it has become clear that the best method by far is the Random Forest modeling, as its predictions were consistently and significantly closer to the actual value of the test data, as compared to the other methods. The second-best method was the GLMULTI created multiple linear regression models, as their predictions were still significantly close to the actual test data values, though not to the extent of the Random Forest models. Furthermore, the Random Forest models are only strengthened with each additional week, as it appears that there is a trend in the direction of performance for several positions on the weekly and seasonal level. Though this trend is unclear at this exact moment (would need to evaluate with time series data), the Random Forest models seemed to have adapted with relative ease and success. Due to the Random Forest and its ease to create, modify, and analyze, this model selection seems more than ideal for weekly and seasonal performance predictions.
The biggest issue that arose from several of the multiple linear regression models, was the tendency for the higher order interactions to create unnecessary complications in the models. Since GLMULTI can reach a max interaction level of two, it appears that the most impactful interactions are at the second level. Additionally, the GLMULTI models that did not contain interactions were substantially less accurate than the GLMULTI models that contain interactions for almost all cases. After complete analysis, it appears that interactions between many of these performance variables are quite significant.
Team specific models have appeared to be relatively successful in predicting accurate performance. Unfortunately, these types of models require a substantial amount of team data to be effective. Team specific models appear to be quite effective for predicting outcomes accurately for matchups at the end of the regular season and post-season.
Simply put, Random Forest models are the best method to predict all performance statistics on a weekly and seasonal basis. Though, GLMULTI, and other occasional simple linear regression models have shown relatively close results in a small percentage of cases. Team specific models can be utilized effectively during the end stretch of the season, but general models are more effective for the beginning and middle parts of the season.
Factor Relationships:
Numerous significant factor relationships had been discovered. Though the factor relationships found have been undeniably influential on performance prediction, these relationships remain predominantly untested. A substantial percentage of the factor relationships in the less effective models appear to be false positives, though certainty cannot be assured unless appropriately tested. The method of selecting the most probable factor relationships was to analyze the most effective models of prediction to measure the presence and scope of said factor relationships. Due to the extent of the significant factor relationships found, individual relationships cannot be discussed at length without appropriate testing. All factor relationships identified in the Random Forest modeling and “GLMULTI” modeling can be found in the “File Reference Section”, by pressing the “RF AND GLMULTI FACTORS” button, which is linked to the output for both.
MPCA Conclusion:</p>
<p>When applied to a matchup scenario, the most advantageous models provided accurate estimates that reflected a comprehensive understanding of most of the consequential factor relationships. These advantageous models are excellent baseline models to continually improve upon in the future.
Note: The analysis, conclusion, and suggested strategies are tailored for the Rams, as this is a case study of situational analysis.</p>
<p>Estimated Impact of Strategy for Arizona Match Up:</p>
<figure><img src="https://emr89.github.io/images/FP1.png"/>
</figure>

<p>The application of the best models found in my research has proven to be as beneficial as I had hoped. The scope of the models applied appears to be quite parallel to the outcome of the game. In fact, the statistical models applied clearly reflects the outcome of the suggested strategy in my conclusion. My strategy, located in the “Match Up Analysis and Game plan: MPCA” section, suggested several notions, but focused on versatility in the running game by tampering with our short passing game, and increasing blitzes and letting Arizona take long pass play attempts down the field because the match ups were favorable for the Rams.
Before any strategic adjustments, the Rams would have been slightly favored to win the match up with a win probability of around 55.45%. The score would have been around 23 – 17 on average, which means the Rams would have scored around 3 touchdowns and one field goal, and Arizona would have scored around 2 touchdowns and a field goal. The Rams would have passed for 226 yards and around 2 touchdowns after 32/33 attempts. The Rams’ remaining touchdown had a probability of around 46% of being a rushing touchdown. The remaining probability for the remaining points would have either been allocated to a defensive touchdown or made field goals. The Rams’ offense would have had around 22 first downs, and around 1 turnover (interception or fumble, 63.5% chance being an interception).  The Rams’ Defense would have allowed around 19 first downs, with 228 passing yards, 115 rushing yards, and would have probably come away with one takeaway (33.6% chance of an interception, 66.4% chance of a fumble recovery). Arizona’s Offense would have passed for one touchdown after 31/32 attempts and had a 50/50 chance of scoring 1 rushing touchdown after 17/18 rushing attempts. If Arizona did not score a rushing touchdown, it would have been a defensive touchdown or a pair of field goals.
After strategic adjustments, the Rams would have been greatly favored to win the match with a win probability of around 73.74%. The score would have been around 24 – 18 on average, which means the Rams would have scored around 3 touchdowns and one field goal, and Arizona would have scored around 2 touchdowns and a field goal. The major distinction from the pre-adjustment predictions to the post-adjustment predictions, is the level of certainty of the score, as a full touchdown lead for the Rams would have been highly probable in the post-adjustment scenario versus only slightly probable in the pre-adjustment scenario. The variability of the score difference was greatly reduced after the adjustments, which means that though the win would have only been by around one touchdown, the strategy implemented reduced any unnecessary risk and victory was much more of a guarantee than before. The Rams would have passed for 218 yards and around 2 touchdowns after 32/33 attempts. The Rams’ remaining touchdown had a probability of around 33.86% of being a rushing touchdown. The remaining probability for the remaining points would have either been allocated to a defensive touchdown or made field goals. The Rams’ offense would have had around 21 first downs, and possibly 1 turnover (interception or fumble, 25.36% chance of being an interception).  A major distinction to note is that the probability of a turnover and interception from pre-adjustment to post adjustment drops significantly, though 1 turnover is still probable. The Rams’ Defense would have allowed around 19 first downs, with 208 passing yards, 115 rushing yards, and would have probably come away with one takeaway (20.8% chance of an interception, 79.2% chance of a fumble recovery). Arizona’s Offense would have passed for one touchdown after 33/34 attempts and had a 50/50 chance of scoring 1 rushing touchdown after 16/17 rushing attempts. If Arizona did not score a rushing touchdown, it would have been a defensive touchdown or a pair of field goals.
After comparing the results from the week 17 match up against the performance predictions from my acquired statistical models, it is clear that the models acquired capture the essential performance factor relationships, while still being applicable to any team in the league. When analyzing the predictions, it appears that the only issue with the models are that some of the predictions are continually underpredicted for two variables: the number or passing attempts and the total score values. The hypothesize reason for the constant underprediction for score is the datasets exclusion of any points obtained by kickers and special teams, which will constantly have a negative effect on the model, as kickers consistently have a direct impact on the score. The underpredicted values for passing attempts appear to be more of an unknown, but it does appear that some factor is missing from the dataset.
The conclusion is that the acquired best models in this study can already serve as an excellent base for prediction for any match up in the league, while still having the potential for improvement.</p>
<h4 id="final-model-summaries">Final Model Summaries:</h4>
<h5 id="note-though-not-all-the-results-of-the-models-were-exeptionally-high-this-was-an-introductory-project-to-machine-learning-and-the-first-step-at-trying-to-utilize-machine-learning-for-strategy-the-next-step-of-the-project-or-next-project-would-take-those-same-models-and-find-the-best-model-subset-with-the-highest-r2">Note: Though not all the results of the models were exeptionally high, this was an introductory project to machine learning and the first step at trying to utilize machine learning for strategy. The next step of the project or next project would take those same models and find the best model subset with the highest R^2.</h5>
<h3 id="irf1">IRF1</h3>
<p>Call:
randomForest(formula = outcome ~ COMP + EM + CTCH + AYTS_OPP +      COMP_OPP + SEP_OPP + CTCH_OPP + YACR_OPP, data = train_WP_outcome,      importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 2</p>
<pre><code>       Mean of squared residuals: 0.2132148
                 % Var explained: 14.62
</code></pre>
<h3 id="irf2">IRF2</h3>
<p>Call:
randomForest(formula = TEAMS ~ CAY + AYTS + COMP + EFF + AVG +      SEP + TAY + CTCH + YACR + TT_OPP + CAY_OPP + AYTS_OPP + EFF_OPP +      EM_OPP + TLOS_OPP + TAY_OPP + CTCH_OPP, data = train_WP_TEAMS,      importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 5</p>
<pre><code>       Mean of squared residuals: 73.57855
                 % Var explained: 17.1
</code></pre>
<h3 id="irf3">IRF3</h3>
<p>Call:
randomForest(formula = OPPS ~ TT + AGG + EM + CAY_OPP + AYTS_OPP +      EM_OPP + CTCH_OPP + YACR_OPP, data = train_WP_OPPS, importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 2</p>
<pre><code>       Mean of squared residuals: 70.60563
                 % Var explained: 33.85
</code></pre>
<h3 id="irf4">IRF4</h3>
<p>Call:
randomForest(formula = FD ~ AGG + AYTS + COMP + EFF + AVG + SEP +      TAY + CTCH + YACR + TT_OPP + AYTS_OPP + COMP_OPP + EFF_OPP +      EM_OPP + AVG_OPP + CUSH_OPP + SEP_OPP + YACR_OPP, data = train_WP_FD,      importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 6</p>
<pre><code>       Mean of squared residuals: 18.09063
                 % Var explained: 24.11
</code></pre>
<h3 id="irf5">IRF5</h3>
<p>Call:
randomForest(formula = PY ~ COMP + EFF + TLOS + AVG + CUSH +      SEP + TAY + CTCH + YACR + CAY_OPP + AGG_OPP + AYTS_OPP +      COMP_OPP + EFF_OPP + EM_OPP + TLOS_OPP + AVG_OPP + CUSH_OPP +      SEP_OPP + TAY_OPP + YACR_OPP, data = train_WP_PY, importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 7</p>
<pre><code>       Mean of squared residuals: 5486.937
                 % Var explained: 11.25
</code></pre>
<h3 id="irf6">IRF6</h3>
<p>Call:
randomForest(formula = RY ~ TT + CAY + AGG + AYTS + COMP + EFF +      EM + TLOS + AVG + CUSH + SEP + TAY + CTCH + YACR + TT_OPP +      CAY_OPP + AGG_OPP + AYTS_OPP + COMP_OPP + EFF_OPP + EM_OPP +      TLOS_OPP + AVG_OPP + CUSH_OPP + SEP_OPP + TAY_OPP + CTCH_OPP +      YACR_OPP, data = train_WP_RY, importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 9</p>
<pre><code>       Mean of squared residuals: 1538.505
                 % Var explained: 37.71
</code></pre>
<h3 id="irf7">IRF7</h3>
<p>Call:
randomForest(formula = TO ~ TT + CAY + AGG + AYTS + COMP + EFF +      EM + TLOS + AVG + CUSH + SEP + TAY + CTCH + YACR + TT_OPP +      CAY_OPP + AGG_OPP + AYTS_OPP + COMP_OPP + EFF_OPP + EM_OPP +      TLOS_OPP + AVG_OPP + CUSH_OPP + SEP_OPP + TAY_OPP + CTCH_OPP +      YACR_OPP, data = train_WP_TO, importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 9</p>
<pre><code>       Mean of squared residuals: 1.719627
                 % Var explained: -0.37
</code></pre>
<h3 id="irf8">IRF8</h3>
<p>Call:
randomForest(formula = DFD ~ TT + CAY + AGG + AYTS + COMP + EFF +      EM + TLOS + AVG + CUSH + SEP + TAY + CTCH + YACR + TT_OPP +      CAY_OPP + AGG_OPP + AYTS_OPP + COMP_OPP + EFF_OPP + EM_OPP +      TLOS_OPP + AVG_OPP + CUSH_OPP + SEP_OPP + TAY_OPP + CTCH_OPP +      YACR_OPP, data = train_WP_DFD, importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 9</p>
<pre><code>       Mean of squared residuals: 24.79874
                 % Var explained: -0.41
</code></pre>
<h3 id="irf9">IRF9</h3>
<p>Call:
randomForest(formula = DPY ~ TT + CAY + AGG + AYTS + COMP + EFF +      EM + TLOS + AVG + CUSH + SEP + TAY + CTCH + YACR + TT_OPP +      CAY_OPP + AGG_OPP + AYTS_OPP + COMP_OPP + EFF_OPP + EM_OPP +      TLOS_OPP + AVG_OPP + CUSH_OPP + SEP_OPP + TAY_OPP + CTCH_OPP +      YACR_OPP, data = train_WP_DPY, importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 9</p>
<pre><code>       Mean of squared residuals: 5967.111
                 % Var explained: 2.93
</code></pre>
<h3 id="irf10">IRF10</h3>
<p>Call:
randomForest(formula = DRY ~ TT + CAY + AGG + AYTS + COMP + EFF +      EM + TLOS + AVG + CUSH + SEP + TAY + CTCH + YACR + TT_OPP +      CAY_OPP + AGG_OPP + AYTS_OPP + COMP_OPP + EFF_OPP + EM_OPP +      TLOS_OPP + AVG_OPP + CUSH_OPP + SEP_OPP + TAY_OPP + CTCH_OPP +      YACR_OPP, data = train_WP_DRY, importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 9</p>
<pre><code>       Mean of squared residuals: 1175.036
                 % Var explained: 37.64
</code></pre>
<h3 id="irf11">IRF11</h3>
<p>Call:
randomForest(formula = DTO ~ TT + CAY + AGG + AYTS + COMP + EFF +      EM + TLOS + AVG + CUSH + SEP + TAY + CTCH + YACR + TT_OPP +      CAY_OPP + AGG_OPP + AYTS_OPP + COMP_OPP + EFF_OPP + EM_OPP +      TLOS_OPP + AVG_OPP + CUSH_OPP + SEP_OPP + TAY_OPP + CTCH_OPP +      YACR_OPP, data = train_WP_DTO, importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 9</p>
<pre><code>       Mean of squared residuals: 1.845015
                 % Var explained: -4.11
</code></pre>
<h3 id="irf12">IRF12</h3>
<p>Call:
randomForest(formula = ATT ~ TT + CAY + AGG + AYTS + COMP + EFF +      EM + TLOS + AVG + CUSH + SEP + TAY + CTCH + YACR + TT_OPP +      CAY_OPP + AGG_OPP + AYTS_OPP + COMP_OPP + EFF_OPP + EM_OPP +      TLOS_OPP + AVG_OPP + CUSH_OPP + SEP_OPP + TAY_OPP + CTCH_OPP +      YACR_OPP, data = train_WP_ATT, importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 9</p>
<pre><code>       Mean of squared residuals: 65.37034
                 % Var explained: 1.74
</code></pre>
<h3 id="irf13">IRF13</h3>
<p>Call:
randomForest(formula = TD ~ TT + CAY + AGG + AYTS + COMP + EFF +      EM + TLOS + AVG + CUSH + SEP + TAY + CTCH + YACR + TT_OPP +      CAY_OPP + AGG_OPP + AYTS_OPP + COMP_OPP + EFF_OPP + EM_OPP +      TLOS_OPP + AVG_OPP + CUSH_OPP + SEP_OPP + TAY_OPP + CTCH_OPP +      YACR_OPP, data = train_WP_TD, importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 9</p>
<pre><code>       Mean of squared residuals: 1.456711
                 % Var explained: 12.32
</code></pre>
<h3 id="irf14">IRF14</h3>
<p>Call:
randomForest(formula = INT ~ TT + CAY + AGG + AYTS + COMP + EFF +      EM + TLOS + AVG + CUSH + SEP + TAY + CTCH + YACR + TT_OPP +      CAY_OPP + AGG_OPP + AYTS_OPP + COMP_OPP + EFF_OPP + EM_OPP +      TLOS_OPP + AVG_OPP + CUSH_OPP + SEP_OPP + TAY_OPP + CTCH_OPP +      YACR_OPP, data = train_WP_INT, importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 9</p>
<pre><code>       Mean of squared residuals: 1.031183
                 % Var explained: -0.44
</code></pre>
<h3 id="irf15">IRF15</h3>
<p>Call:
randomForest(formula = RUSHATT ~ TT + CAY + AGG + AYTS + COMP +      EFF + EM + TLOS + AVG + CUSH + SEP + TAY + CTCH + YACR +      TT_OPP + CAY_OPP + AGG_OPP + AYTS_OPP + COMP_OPP + EFF_OPP +      EM_OPP + TLOS_OPP + AVG_OPP + CUSH_OPP + SEP_OPP + TAY_OPP +      CTCH_OPP + YACR_OPP, data = train_WP_RUSHATT, importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 9</p>
<pre><code>       Mean of squared residuals: 38.96676
                 % Var explained: -8.9
</code></pre>
<h3 id="irf16">IRF16</h3>
<p>Call:
randomForest(formula = RUSHTD ~ TT + CAY + AGG + AYTS + COMP +      EFF + EM + TLOS + AVG + CUSH + SEP + TAY + CTCH + YACR +      TT_OPP + CAY_OPP + AGG_OPP + AYTS_OPP + COMP_OPP + EFF_OPP +      EM_OPP + TLOS_OPP + AVG_OPP + CUSH_OPP + SEP_OPP + TAY_OPP +      CTCH_OPP + YACR_OPP, data = train_WP_RUSHTD, importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 9</p>
<pre><code>       Mean of squared residuals: 0.5641411
                 % Var explained: -5.17
</code></pre>
<h3 id="irf17">IRF17</h3>
<p>Call:
randomForest(formula = ATT_OPP ~ TT + CAY + AGG + AYTS + COMP +      EFF + EM + TLOS + AVG + CUSH + SEP + TAY + CTCH + YACR +      TT_OPP + CAY_OPP + AGG_OPP + AYTS_OPP + COMP_OPP + EFF_OPP +      EM_OPP + TLOS_OPP + AVG_OPP + CUSH_OPP + SEP_OPP + TAY_OPP +      CTCH_OPP + YACR_OPP, data = train_WP_ATT_OPP, importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 9</p>
<pre><code>       Mean of squared residuals: 73.79984
                 % Var explained: -7.15
</code></pre>
<h3 id="irf18">IRF18</h3>
<p>Call:
randomForest(formula = TD_OPP ~ TT + CAY + AGG + AYTS + COMP +      EFF + EM + TLOS + AVG + CUSH + SEP + TAY + CTCH + YACR +      TT_OPP + CAY_OPP + AGG_OPP + AYTS_OPP + COMP_OPP + EFF_OPP +      EM_OPP + TLOS_OPP + AVG_OPP + CUSH_OPP + SEP_OPP + TAY_OPP +      CTCH_OPP + YACR_OPP, data = train_WP_TD_OPP, importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 9</p>
<pre><code>       Mean of squared residuals: 1.060959
                 % Var explained: 16.24
</code></pre>
<h3 id="irf19">IRF19</h3>
<p>Call:
randomForest(formula = INT_OPP ~ TT + CAY + AGG + AYTS + COMP +      EFF + EM + TLOS + AVG + CUSH + SEP + TAY + CTCH + YACR +      TT_OPP + CAY_OPP + AGG_OPP + AYTS_OPP + COMP_OPP + EFF_OPP +      EM_OPP + TLOS_OPP + AVG_OPP + CUSH_OPP + SEP_OPP + TAY_OPP +      CTCH_OPP + YACR_OPP, data = train_WP_INT_OPP, importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 9</p>
<pre><code>       Mean of squared residuals: 1.163437
                 % Var explained: -8.76
</code></pre>
<h3 id="irf20">IRF20</h3>
<p>Call:
randomForest(formula = RUSHATT_OPP ~ TT + CAY + AGG + AYTS +      COMP + EFF + EM + TLOS + AVG + CUSH + SEP + TAY + CTCH +      YACR + TT_OPP + CAY_OPP + AGG_OPP + AYTS_OPP + COMP_OPP +      EFF_OPP + EM_OPP + TLOS_OPP + AVG_OPP + CUSH_OPP + SEP_OPP +      TAY_OPP + CTCH_OPP + YACR_OPP, data = train_WP_RUSHATT_OPP,      importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 9</p>
<pre><code>       Mean of squared residuals: 29.57156
                 % Var explained: -3.64
</code></pre>
<h3 id="irf21">IRF21</h3>
<p>Call:
randomForest(formula = RUSHTD_OPP ~ TT + CAY + AGG + AYTS + COMP +      EFF + EM + TLOS + AVG + CUSH + SEP + TAY + CTCH + YACR +      TT_OPP + CAY_OPP + AGG_OPP + AYTS_OPP + COMP_OPP + EFF_OPP +      EM_OPP + TLOS_OPP + AVG_OPP + CUSH_OPP + SEP_OPP + TAY_OPP +      CTCH_OPP + YACR_OPP, data = train_WP_RUSHTD_OPP, importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 9</p>
<pre><code>       Mean of squared residuals: 0.7837694
                 % Var explained: -8.18
</code></pre>
<h3 id="arfm1">ARFM1</h3>
<p>Call:
randomForest(formula = outcome ~ TT + CAY + AGG + AYTS + COMP +      Week + EFF + EM + TLOS + AVG + CUSH + SEP + TAY + CTCH +      YACR, data = train_WP_outcome, importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 5</p>
<pre><code>       Mean of squared residuals: 0.2240506
                 % Var explained: 9.37
</code></pre>
<h3 id="arfm2">ARFM2</h3>
<p>Call:
randomForest(formula = TEAMS ~ TT + CAY + AGG + AYTS + COMP +      Week + EFF + EM + TLOS + AVG + CUSH + SEP + TAY + CTCH +      YACR, data = train_WP_TEAMS, importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 5</p>
<pre><code>       Mean of squared residuals: 76.02217
                 % Var explained: 25.46
</code></pre>
<h3 id="arfm3">ARFM3</h3>
<p>Call:
randomForest(formula = OPPS ~ TT + CAY + AGG + AYTS + COMP +      Week + EFF + EM + TLOS + AVG + CUSH + SEP + TAY + CTCH +      YACR, data = train_WP_OPPS, importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 5</p>
<pre><code>       Mean of squared residuals: 98.64449
                 % Var explained: -4.19
</code></pre>
<h3 id="arfm4">ARFM4</h3>
<p>Call:
randomForest(formula = FD ~ TT + CAY + AGG + AYTS + COMP + Week +      EFF + EM + TLOS + AVG + CUSH + SEP + TAY + CTCH + YACR, data = train_WP_FD,      importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 5</p>
<pre><code>       Mean of squared residuals: 19.97174
                 % Var explained: 19.95
</code></pre>
<h3 id="arfm5">ARFM5</h3>
<p>Call:
randomForest(formula = PY ~ TT + CAY + AGG + AYTS + COMP + Week +      EFF + EM + TLOS + AVG + CUSH + SEP + TAY + CTCH + YACR, data = train_WP_PY,      importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 5</p>
<pre><code>       Mean of squared residuals: 4473.697
                 % Var explained: 28.74
</code></pre>
<h3 id="arfm6">ARFM6</h3>
<p>Call:
randomForest(formula = RY ~ TT + CAY + AGG + AYTS + COMP + Week +      EFF + EM + TLOS + AVG + CUSH + SEP + TAY + CTCH + YACR, data = train_WP_RY,      importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 5</p>
<pre><code>       Mean of squared residuals: 1516.127
                 % Var explained: 43.72
</code></pre>
<h3 id="arfm7">ARFM7</h3>
<p>Call:
randomForest(formula = TO ~ TT + CAY + AGG + AYTS + COMP + Week +      EFF + EM + TLOS + AVG + CUSH + SEP + TAY + CTCH + YACR, data = train_WP_TO,      importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 5</p>
<pre><code>       Mean of squared residuals: 1.525499
                 % Var explained: -0.48
</code></pre>
<h3 id="arfm8">ARFM8</h3>
<p>Call:
randomForest(formula = DFD ~ TT + CAY + AGG + AYTS + COMP + Week +      EFF + EM + TLOS + AVG + CUSH + SEP + TAY + CTCH + YACR, data = train_WP_DFD,      importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 5</p>
<pre><code>       Mean of squared residuals: 25.46017
                 % Var explained: -4.4
</code></pre>
<h3 id="arfm9">ARFM9</h3>
<p>Call:
randomForest(formula = DPY ~ TT + CAY + AGG + AYTS + COMP + Week +      EFF + EM + TLOS + AVG + CUSH + SEP + TAY + CTCH + YACR, data = train_WP_DPY,      importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 5</p>
<pre><code>       Mean of squared residuals: 6872.24
                 % Var explained: -6.06
</code></pre>
<h3 id="arfm10">ARFM10</h3>
<p>Call:
randomForest(formula = DRY ~ TT + CAY + AGG + AYTS + COMP + Week +      EFF + EM + TLOS + AVG + CUSH + SEP + TAY + CTCH + YACR, data = train_WP_DRY,      importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 5</p>
<pre><code>       Mean of squared residuals: 2832.362
                 % Var explained: -9.72
</code></pre>
<h3 id="arfm11">ARFM11</h3>
<p>Call:
randomForest(formula = DTO ~ TT + CAY + AGG + AYTS + COMP + Week +      EFF + EM + TLOS + AVG + CUSH + SEP + TAY + CTCH + YACR, data = train_WP_DTO,      importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 5</p>
<pre><code>       Mean of squared residuals: 1.948134
                 % Var explained: -10.47
</code></pre>
<h3 id="arfm12">ARFM12</h3>
<p>Call:
randomForest(formula = TT ~ CAY + AGG + AYTS + COMP + Week +      EFF + EM + TLOS + AVG + CUSH + SEP + TAY + CTCH + YACR, data = train_WP_TT,      importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 4</p>
<pre><code>       Mean of squared residuals: 0.06779569
                 % Var explained: 7.22
</code></pre>
<h3 id="arfm13">ARFM13</h3>
<p>Call:
randomForest(formula = CAY ~ TT + AGG + AYTS + COMP + Week +      EFF + EM + TLOS + AVG + CUSH + SEP + TAY + CTCH + YACR, data = train_WP_CAY,      importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 4</p>
<pre><code>       Mean of squared residuals: 2.824214
                 % Var explained: 47.38
</code></pre>
<h3 id="arfm14">ARFM14</h3>
<p>Call:
randomForest(formula = AGG ~ TT + CAY + AYTS + COMP + Week +      EFF + EM + TLOS + AVG + CUSH + SEP + TAY + CTCH + YACR, data = train_WP_AGG,      importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 4</p>
<pre><code>       Mean of squared residuals: 41.5984
                 % Var explained: 21.67
</code></pre>
<h3 id="arfm15">ARFM15</h3>
<p>Call:
randomForest(formula = LCAD ~ TT + CAY + AGG + AYTS + COMP +      Week + EFF + EM + TLOS + AVG + CUSH + SEP + TAY + CTCH +      YACR, data = train_WP_LCAD, importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 5</p>
<pre><code>       Mean of squared residuals: 47.05977
                 % Var explained: 31.39
</code></pre>
<h3 id="arfm16">ARFM16</h3>
<p>Call:
randomForest(formula = AYTS ~ TT + CAY + AGG + COMP + Week +      EFF + EM + TLOS + AVG + CUSH + SEP + TAY + CTCH + YACR, data = train_WP_AYTS,      importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 4</p>
<pre><code>       Mean of squared residuals: 2.455694
                 % Var explained: 54.88
</code></pre>
<h3 id="arfm17">ARFM17</h3>
<p>Call:
randomForest(formula = ATT ~ TT + CAY + AGG + AYTS + COMP + Week +      EFF + EM + TLOS + AVG + CUSH + SEP + TAY + CTCH + YACR, data = train_WP_ATT,      importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 5</p>
<pre><code>       Mean of squared residuals: 66.3464
                 % Var explained: 4.48
</code></pre>
<h3 id="arfm18">ARFM18</h3>
<p>Call:
randomForest(formula = TD ~ TT + CAY + AGG + AYTS + COMP + Week +      EFF + EM + TLOS + AVG + CUSH + SEP + TAY + CTCH + YACR, data = train_WP_TD,      importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 5</p>
<pre><code>       Mean of squared residuals: 1.126963
                 % Var explained: 24.65
</code></pre>
<h3 id="arfm19">ARFM19</h3>
<p>Call:
randomForest(formula = INT ~ TT + CAY + AGG + AYTS + COMP + Week +      EFF + EM + TLOS + AVG + CUSH + SEP + TAY + CTCH + YACR, data = train_WP_INT,      importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 5</p>
<pre><code>       Mean of squared residuals: 0.9904124
                 % Var explained: -1.91
</code></pre>
<h3 id="arfm20">ARFM20</h3>
<p>Call:
randomForest(formula = COMP ~ TT + CAY + AGG + AYTS + Week +      EFF + EM + TLOS + AVG + CUSH + SEP + TAY + CTCH + YACR, data = train_WP_COMP,      importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 4</p>
<pre><code>       Mean of squared residuals: 57.88782
                 % Var explained: 41.18
</code></pre>
<h3 id="arfm21">ARFM21</h3>
<p>Call:
randomForest(formula = RUSHATT ~ TT + CAY + AGG + AYTS + COMP +      Week + EFF + EM + TLOS + AVG + CUSH + SEP + TAY + CTCH +      YACR, data = train_WP_RUSHATT, importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 5</p>
<pre><code>       Mean of squared residuals: 34.97956
                 % Var explained: 1.09
</code></pre>
<h3 id="arfm22">ARFM22</h3>
<p>Call:
randomForest(formula = RUSHTD ~ TT + CAY + AGG + AYTS + COMP +      Week + EFF + EM + TLOS + AVG + CUSH + SEP + TAY + CTCH +      YACR, data = train_WP_RUSHTD, importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 5</p>
<pre><code>       Mean of squared residuals: 0.585507
                 % Var explained: 6.26
</code></pre>
<h3 id="arfm23">ARFM23</h3>
<p>Call:
randomForest(formula = EFF ~ TT + CAY + AGG + AYTS + COMP + Week +      EM + TLOS + AVG + CUSH + SEP + TAY + CTCH + YACR, data = train_WP_EFF,      importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 4</p>
<pre><code>       Mean of squared residuals: 54.53939
                 % Var explained: 28.52
</code></pre>
<h3 id="arfm24">ARFM24</h3>
<p>Call:
randomForest(formula = EM ~ TT + CAY + AGG + AYTS + COMP + Week +      EFF + TLOS + AVG + CUSH + SEP + TAY + CTCH + YACR, data = train_WP_EM,      importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 4</p>
<pre><code>       Mean of squared residuals: 319.6627
                 % Var explained: -2.9
</code></pre>
<h3 id="arfm25">ARFM25</h3>
<p>Call:
randomForest(formula = TLOS ~ TT + CAY + AGG + AYTS + COMP +      Week + EFF + EM + AVG + CUSH + SEP + TAY + CTCH + YACR, data = train_WP_TLOS,      importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 4</p>
<pre><code>       Mean of squared residuals: 0.05078868
                 % Var explained: 14.32
</code></pre>
<h3 id="arfm26">ARFM26</h3>
<p>Call:
randomForest(formula = AVG ~ TT + CAY + AGG + AYTS + COMP + Week +      EFF + EM + TLOS + CUSH + SEP + TAY + CTCH + YACR, data = train_WP_AVG,      importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 4</p>
<pre><code>       Mean of squared residuals: 0.7284423
                 % Var explained: 74.59
</code></pre>
<h3 id="arfm27">ARFM27</h3>
<p>Call:
randomForest(formula = CUSH ~ TT + CAY + AGG + AYTS + COMP +      Week + EFF + EM + TLOS + AVG + SEP + TAY + CTCH + YACR, data = train_WP_CUSH,      importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 4</p>
<pre><code>       Mean of squared residuals: 1.154857
                 % Var explained: -0.39
</code></pre>
<h3 id="arfm28">ARFM28</h3>
<p>Call:
randomForest(formula = SEP ~ TT + CAY + AGG + AYTS + COMP + Week +      EFF + EM + TLOS + AVG + CUSH + TAY + CTCH + YACR, data = train_WP_SEP,      importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 4</p>
<pre><code>       Mean of squared residuals: 0.3579043
                 % Var explained: 26.45
</code></pre>
<h3 id="arfm29">ARFM29</h3>
<p>Call:
randomForest(formula = TAY ~ TT + CAY + AGG + AYTS + COMP + Week +      EFF + EM + TLOS + AVG + CUSH + SEP + CTCH + YACR, data = train_WP_TAY,      importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 4</p>
<pre><code>       Mean of squared residuals: 7.142795
                 % Var explained: 26.22
</code></pre>
<h3 id="arfm30">ARFM30</h3>
<p>Call:
randomForest(formula = CTCH ~ TT + CAY + AGG + AYTS + COMP +      Week + EFF + EM + TLOS + AVG + CUSH + SEP + TAY + YACR, data = train_WP_CTCH,      importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 4</p>
<pre><code>       Mean of squared residuals: 117.2276
                 % Var explained: 33.95
</code></pre>
<h3 id="arfm31">ARFM31</h3>
<p>Call:
randomForest(formula = YACR ~ TT + CAY + AGG + AYTS + COMP +      Week + EFF + EM + TLOS + AVG + CUSH + SEP + TAY + CTCH, data = train_WP_YACR,      importance = TRUE)
Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 4</p>
<pre><code>       Mean of squared residuals: 7.351743
                 % Var explained: 0.11
</code></pre>
<h3 id="match-up-analysis-and-game-plan-mpca">Match Up Analysis and Game Plan: MPCA</h3>
<h4 id="rams-comparative-analysis">Rams’ Comparative Analysis:</h4>
<p>The Rams’ worst comparable performance statistic was related to fourth downs. The Rams held a positional z score for fourth down percent of 2.47, which indicates that the Rams were the worst team in the league for fourth down percent. To analyze this statistic, we must include that the Rams also had a positional z score of 14.65 for fourth down attempts and a positional z score of 5.25 in fourth downs made. The data shows that though the Rams rarely attempted fourth downs, as the Rams were amongst the worst five teams in the league for fourth down attempts. The Rams also were the second worst team in the league for fourth down’s made, and therefore had the worst fourth down percentage in the league. The extrapolation of the data highly suggests an issue with the coaching and the situational analysis related to fourth down decisions. Though whomever was responsible for the decision to attempt a fourth down play was incredibly hesitant, which is shown by the lack of attempts, their situational analysis was lacking for fourth down conditions. This resulted in almost every fourth down attempt ending in failure. This issue could be easily solved with one of the following suggestions. First, a researched formula based on significant factors that lead to fourth down success. A simple trick for convenience is to create a phone app with a simple interface so that the calculation could be done by an individual at a moment’s notice during the game. Second, whomever is making the decision to attempt a fourth down play could have a short seminar in the importance of situational factors and how to balance them to make an accurate assessment of the situation. Third, it is possible that specific play calls for fourth down attempts are conflicting with the situational details and strengths the Rams’ offense, and therefore the best solution is to accurately assess the offense so that the play calls will be directed towards the offense’s strengths in fourth down situations.
The Rams’ most costly performance statistic is their quarterback’s drop in accuracy for the 2019 season. The Rams’ completion percentage positional score is 37.66, which means that his completion percentage was ranked 20th in the league. Not only is this positional score harmful itself, but if you look at the Rams’ third down statistics, there seems to be missed opportunities. The Rams’ third down percent is 45.81, which is around average for the NFL, as the Rams have the 17th best third down percent. Additionally, the Rams’ first down percent score is 56.82, which is ranked 14th best in the league, or a little above average. The Rams’ offense has been keeping pace with the average offense performance of the NFL despite their quarterback’s low accuracy score. How can this be possible? A possible suggestion is the Rams’ ability to create medium length explosive plays. The Rams’ positional score for “LCAD”, which is the longest completion, is 94.59, which means that the Rams’ quarterback has thrown the third longest completed pass in the league. Additionally, the Rams’ positional score for “20+”, which is the number of 20 or more-yard passes completed, is 96.79, which means that the Rams’ quarterback has completed the second most passes of 20 yards or more. The average separation that the Rams’ receiver creates is 3.28, which is almost a full standard deviation higher than the average separation for the league, as the league average is 2.86 and the standard deviation is 0.46, which means that the Rams’ receivers’ ability to get open is not an issue. Subsequently, the Rams’ average receiver catch percentage is slightly above the average for the NFL, as the Rams’ average is 66.4, and the league average is 64.3 with a standard deviation of 7.41, which means that the receivers can only be a minimal to slight explanation for the quarterbacks lack of completion percentage. The positional scores indicate that the when connection between quarterback and receivers do happen, they are explosive, and can do a lot of damage against the defense. The positional scores also show the quarterback’s potential, as he is one of the best in the league at deep passing. The issue comes from the inconsistency of the completions. Inconsistency is cured by two major themes: fundamentals and practice.
The Rams’ most disguised issue is their overreliance on the passing game. Though the Rams’ passing yards positional score is 88.3, which was fourth best in the league at the time, the Rams’ passing attempts positional score is 86.43, which means the Rams had the 5th highest amount of passing plays in the league. The Rams have attempted so many passes during the season that even though the Rams’ number of interceptions had a positional score of 90.76 which was around fourth worst in the league at the time, The Rams’ interception RATIO positional score was 26.29, which means that the Rams were the 8th best team for interceptions per attempt ratio. Now the impacts of an overreliance on the passing game are mixed with positive and negative consequences, a definite negative consequence is the absence of surprise. A defensive coordinator’s hardest job is determining whether the opponent’s next offensive play will be pass or run, therefore lowering the probability of successfully calling the right defensive formation to best counter the offensive play. When the element of surprise is lost, and the defensive coordinator has relative certainty of the offensive play call, his probability of choosing the defensive formation to successfully defend against the offense’s next play is escalated substantially.
The strength of the Rams’ defense is the Rams’ defensive front, as they consistently perform higher than the average of the league for pass rush variables. The following statistics are weekly defensive averages for the entire defensive unit compared to the rest of the league. The average amount of sacks per week was 1.23, with a standard deviation of 0.533, as compared to the entire league average of 0.762 with a standard deviation of 0.659. The Rams consistently had a higher average of sacks than the rest of the league each week. The sack yards lost for the Rams’ defensive front was 7.63 yards, with a standard deviation of 5.21, as compared to the league’s average of 5.2 yards with a standard deviation of 5.58, which means that the defensive front consistently sacks the quarterback deep behind the line of scrimmage. The average number of QB hits per week for the defensive unit is 1.71 with a standard deviation of 1.05, compared to the league’s average of 1.11 with a standard deviation of 1.03, which means that the defensive pass rush is consistently getting to the QB more than the rest of the league.
The defense, in its entirety, seems to be around average for physicality in the league. The following statistics are weekly defensive averages for the entire defensive unit compared to the rest of the league. The average number of tackles per game for a Rams’ defensive player is around 2.89, with a standard deviation of 1.45, as compared to the rest of the league with an average of 2.5 with a standard deviation of 2.01, which means that the Rams are consistently slightly above average for the number of tackles on a weekly basis. The average number of tackle assists for a Rams’ defensive player is around 1.2, with a standard deviation of 1.28, as the compared to the league average of 1.11 with a standard deviation of 1.27, which means that the Rams consistently are barely above average, if not essentially average, for tackling assists on a weekly basis. Both of variables of tackles and assists indicate that the physicality and urgency of the defense is around the average of the league. Though tackles overall indicate more than just defensive performance, such as relative time of possession of the offense as complimentary to the defensive number of tackles, assists indicate more defensive performance traits, such as urgency to swarm the ball carrier. An emphasis on pursuing the ball carrier and defensive urgency would increase the number of defensive assists and would be beneficial for the entire defense.
The main underlying issue with the defense is turnovers, interceptions, and fumbles, which both directly impact defensive and offensive performance. When it comes to fumbles, the defense struggles the most with “finishing” and capitalizing on the fumble. This is quite apparent when looking at the fact that the Rams’ defense is around the league average for forcing fumbles but is relatively below the league average for recovering those forced fumbles. The average number of forced fumbles for a Rams’ defensive player per week is 0.143 with a standard deviation of 0.355, as compared to the league average of 0.136 with a standard deviation of 0.371, which is essentially average. Now, an average number of fumble recoveries for a Rams’ defensive player is 0.0286, with a standard deviation of 0.169, as compared to the league average of 0.0421, with a standard deviation of 0.201, which means that the Rams are consistently slightly below average for fumble recoveries. When it comes to interceptions, all aspects need to be improved upon as they are all consistently slightly below average. The following statistics are from a season long dataset that spans until week 13. The average number of interceptions for a Rams’ defensive player is 0.171, with a standard deviation of 0.543, as compared to the league average of 0.243 with a standard deviation of 0.698, which means that the Rams are consistently below average. The average number of interception yards for a Rams’ defensive player is 1.68 with a standard deviation of 6.9, as compared to the league’s average of 3.12, with a standard deviation of 13.4, which means the Rams were consistently below average for interception return yards. When analyzing interception yards average, interception yards long, and interception TDs, a similar result was found that the Rams’ average for the statistic was consistently slightly below average of the league. Turnovers have been vastly ruled as crucial to the success of a team, as each turnover gives the offense an additional attempt at scoring points while reducing the number of attempts that the opponent have at scoring points, or vice versa. Turnovers are especially important to the Rams as their explosive offense can consistently capitalize on each opportunity, which directly results in a better result for the team.</p>
<p>When it comes to the position of quarterback, though his drop in accuracy and completion percentage has been an issue, an area of praise for him is his decision-making skills. As previously stated, due to the excessive reliance on the passing game, the quarterback has thrown a slightly above average number of interceptions, but when analyzing his interception per attempt ratio, he throws quite a low percent of interceptions. This is a result of his relatively low “AGG%”, which is a measure of the percentage of plays that he throws into tight coverage. The Rams’ quarterback’s AGG average is 11.575, with a standard deviation of 4.86, as compared to the league average of 16.5873, with a standard deviation of 7.095, which means that the Rams’ quarterback is consistently below average for an AGG rate, which shows the innate ability to make effective passing decisions under pressure. When it comes to the Rams’ quarterback’s overall performance and abilities, the results are generally quite positive. The Rams’ quarterback has shown to be able to have a high football IQ due to proper coaching, while also demonstrating that he possesses the abilities to make consistently deep completions, which is a skill that his hard to develop. The only area of his abilities that needs improvement are his fundamentals, which is quite manageable and relatively easy to improve on. The quarterback possesses the innate talents and intelligence to excel in the position, but just requires a little more fundamental development. Once this development is completed, he can prove to be one of the most skilled and dangerous quarterbacks in the league.
On the Rams’ offense, the position group that struggles the most are the running backs. The following statistics are from a weekly rushing dataset. The dataset only looks at running backs that get above 5-10 carries per game for any given week, which essentially means only the team’s top two running backs. The following statistics are the averages for the top running backs on the team compared to the rest of the league, these running backs are considered the essential running backs. The average number of attempts an essential Rams’ running back takes per game is around 15.1, with a standard deviation of 4.755, compared to the league’s average of 15.9, with a standard deviation of 4.55, which means the Rams’ running backs are around average for the number of rushing attempts compared to the rest of the league. The Rams’ rushing performance variables all highlight their struggle to perform even with the average rushing team in the league. The Rams’ essential running back’s average rushing yards per game is around 58.4 with a standard deviation of standard deviation of 24.19, as compared to the league average of 69.4 with a standard deviation of 23.3. The Rams’ essential running back’s average yards per carry is 3.91 with a standard deviation of 0.92, as compared to the league’s average of 4.31, with an average of 1.29. The Rams’ performance in both average yards per carry and total yards per game for their top running backs are relatively below average. Possible explanations might be the time behind the line of scrimmage and the efficiency rate of the running back. The average time the Rams’ essential running backs are behind the line of scrimmage is 2.94, with standard deviation of 0.22, as compared to the league average of 2.82 and a standard deviation of 0.214. The Rams’ running backs are spending a significantly longer amount of time behind the line of scrimmage. Additionally, the Rams’ “EFF” rate highlights another issue. The “EFF” rates the efficiency of the running back, the lower the number, the more of a direct north and south runner the running back is. The Rams’ average EFF is 4.66 with a standard deviation of 1.17, as compared to the league’s average EFF of 4.71 with a standard deviation of 1.16, which means that the Rams are around the average EFF for the league, which means that they are not as efficient with their directional movement as they could be. The only beneficial aspect of the essential running back’s performance is the number of touchdowns. The average number of touchdowns the essential Rams’ running backs score is 0.76 with a standard deviation of 0.79, as compared to the league average of 0.529 with a standard deviation of 0.772, which means that the Rams’ running backs have a significantly higher average of weekly touchdowns as compared to the league’s average essential running back. This surprising statistic is mostly due to the use of the Rams utilization of the running backs, as they appear to be mostly for goal line scenarios and schemes. The Rams’ biggest issue at the running position is the lack of the ability average a higher number of yards per carry to march down the field. The running backs are effective only in goal line scenarios, which restricts the flexibility of the offense, and reveals major weaknesses for the Rams’ offense to the Rams’ opponents.
The most effective and talented position group on the Rams’ offense is their receiving core. As mentioned previously, they create a significant amount more of separation from the defensive backs as compared to the average receiver in the league. Another ability the Rams’ receiver excel in is YAC per reception. The Rams’ average YAC per reception is 5.69 with a standard deviation of 3.27, as compared to the league’s average of 4.52 with a standard deviation of 3.27, which means that the Rams’ receivers are substantially better at collecting YAC compared to the average receiver in the league. This ability to create separation and maintain a higher YAC has led to the Rams’ receivers to consistently have more yards each week than the average receiver, as the Rams’ average is 76.4 yards per game with a standard deviation of 44.4, as compared to the league’s average of 62.2 yards per game with a standard deviation of 44.5. Though the receiving core is quite competent, there are always aspects of their performance that they could improve upon. The Rams’ receivers are around average for the following variables: touchdowns per game, catch percentage per game, and target air yards. For the average number of touchdowns per game, the Rams’ receiver’s average 0.362 with a standard deviation of 0.53, as compared to the league average of 0.38 with a standard deviation of 0.529. This average performance statistic does not line up with the rest of their performance averages but connecting the Rams’ receivers to the Rams’ running back’s averages it has been determined that the average number of touchdowns is due to offensive strategy. The Rams’ offense uses their receivers to march down the field but used the running backs in goal line scenarios to score the touchdowns.  The Rams’ receiver’s average catch percentage can be explained by their quarterback’s slightly below average completion percentage, though not all the blame is on the quarterback. The Rams’ receiver’s average weekly catch percentage is 65.3, with a standard deviation of 15.58, as compared to the league’s average of 63.14 with a standard deviation of 15.6, which means that the Rams’ receivers are essentially average when it comes to catch percentage. The best solution to this problem is constant practice with the starting quarterback. The average target air yards per game for the Rams is 8.9 with a standard deviation of 3.64, as compared to the league’s average of 10.4 with a standard deviation of 3.65, which means that the receivers are being targeted for a substantial less amount of air yards. This issue has little to do with the receivers and more to deal with the following factors: time to throw (offensive line), quarterback accuracy at a farther distance, and offensive game planning. When analyzing why the receivers are targets for less yards than average, an important factor is the average cushion distance the Rams’ receiver’s get. The average cushion for Rams’ receivers is 6.35 with a standard deviation of 1.55, as compared to the league’s average of 5.72 with a standard deviation of 1.55, which means that the Rams’ receivers are given a significantly higher amount of cushion distance, probably due to their YAC and separation. This higher amount of cushion encourages the offensive game plan to include shorter intended air yard throws, so the receivers will not be tightly covered when they make the catch. This game plan also works in the Rams favor as their offensive line provides the league’s average time to throw. Overall, the lower than average intended air yards and target air yards can be easily explained by the situational conditions and efficient offensive game planning.</p>
<h4 id="arizonas-comparative-analysis">Arizona’s Comparative Analysis:</h4>
<p>Arizona’s worst comparable performance statistic is their AYTS, which is average passing yards to the sticks. The positional score of Arizona’s AYTS is 11.3, or the fourth worst in the league and shows that, on average, Arizona’s passes are relatively far behind the sticks. This could be a result of several factors, but other positional factors shed light on some of the highest contributing factors. The positional score for yards per attempted passing has a score of 21.13, which is the seventh worst in the league. Arizona’s quarterback, on average, is throwing relatively short passes, which would be far away from the sticks. Additionally, Arizona’s rush attempts positional score is a 22.73, which around seventh worst for the number of rushing plays, which means that Arizona’s quarterback is throwing those short passes a substantial percentage of the time, which is why their AYTS is so low. Additionally, though it seems contradicting, Arizona has a positional score of 87.96 for “40+” yard completed passes, which means Arizona’s quarterback completes the fifth most 40+ yard passes in the league. These seemingly contradicting pieces of information reveal Arizona’s overreliance on “check downs” or swing passes, as extremely short pass plays would be the only method of lowering the average yards per pass attempt.
Arizona’s most costly comparable performance statistic is their third down efficiency. Arizona’s third down efficiency has a positional score of 23.98, which is around eighth worst in the league. Additionally, Arizona’s positional score for third down attempts is 45.53, which is around average in the league, therefore Arizona is failing to convert on third down a substantial amount of the time. Arizona’s low third down conversion rate highlights Arizona’s inexperience, and possibly a lack of creative play calling. Third down is when the yardage situation required is known to its full extent, and the play type becomes more predictable. The lack of third down conversions show Arizona’s inability to succeed in a “hardnose”, tough execution, style of football.
Arizona’s most disguised issue is their inability to finish drives consistently. Two thirds of the way through the season, the number of total touchdowns for Arizona was 27, and the average for the league was 34 with a standard deviation of 8, which means that Arizona was in the bottom quarter of the league for scoring touchdowns. When looking at team performance for yards, Arizona had an above average amount of yards for the entire offense. Arizona had an average amount of passing yards, as Arizona’s quarterback had 238.8 passing yards per game, but the league average for starting quarterbacks was 246.77 with a standard deviation of 80.08. Arizona had a slightly above average number of weekly rushing yards with an average of 75.2 with a compared to the league’s average of 69.4 and a standard deviation of 23.3. Since Arizona was around the average for yards in the league, their low positional score for touchdowns highlights their inability to finish off drives, which is a lack proper coaching, a lack of experience, and a lack of ability.
Arizona’s defense is relatively mediocre when it comes to talent and individual player performance. The average amount of sacks per week was 0.717 for each player on the defensive front, with a standard deviation of 0.77, as compared to the entire league average of 0.762 with a standard deviation of 0.659. The sack yards lost for Arizona’s defensive front was 4.89 yards, with a standard deviation of 6.14, as compared to the league’s average of 5.2 yards with a standard deviation of 5.58. The average number of QB hits per week for the defensive unit is 1.04 with a standard deviation of 0.917, compared to the league’s average of 1.11 with a standard deviation of 1.03. These factors show that Arizona’s pass rush is around average compared to the rest of the league.
A relatively strong aspect of Arizona’s defense is their physicality. The average number of tackles per game for the average Arizona defensive player is around 3.17, with a standard deviation of 2.68, as compared to the rest of the league with an average of 2.5 with a standard deviation of 2.01. The average number of tackles assists for Arizona’s defensive player is around 1.22, with a standard deviation of 1.31, as the compared to the league average of 1.11 with a standard deviation of 1.27.
Arizona’s best aspect of their defense is the ability to force and recover fumbles. The average number of forced fumbles for Arizona’s defensive player per week is 0.304 with a standard deviation of 0.55, as compared to the league average of 0.136 with a standard deviation of 0.371. The average number of fumble recoveries for Arizona’s defensive player is 0.0807, with a standard deviation of 0.28, as compared to the league average of 0.0421, with a standard deviation of 0.201. Arizona is significantly above average for both forcing fumbles and fumble recoveries. Unfortunately, Arizona’s defense struggles with interceptions and all related factors related to interceptions. The average number of interceptions for Arizona’s defensive player is 0.14, with a standard deviation of 0.516, as compared to the league average of 0.243 with a standard deviation of 0.698. The average number of interception yards for Arizona’s defensive player is 1.91 with a standard deviation of 10.1, as compared to the league’s average of 3.12, with a standard deviation of 13.4. Arizona’s defense does not often intercept the quarterback, and when they occasionally do, they are unable to return the interception for any substantial number of yards.
Arizona’s performance at the quarterback position is mixed bag. One strength of Arizona’s quarterback is his football IQ. Arizona’s AGG average is 13.825, with a standard deviation of 6.29, as compared to the league average of 16.5873, with a standard deviation of 7.095. Due to Arizona’s low AGG percent, Arizona’s interception amount is slightly below average, as Arizona’s interception weekly average is 0.5 with a standard deviation of 0.93, as compared to the league average of 0.754 with a standard deviation of 0.93. As previously mentioned, Arizona’s AYTS is one of the worst in the league, which is probably due to his average below average completed and intended air yards. Arizona’s completed air yards (CAY) is 4.9 with a standard deviation of 2.24, as compared to the league’s average of 6.004 with a standard deviation of 2.14. Arizona’s average intended air yards (IAY) is 6.6 with a standard deviation of 2.19, compared to the league’s average 8.2 with a standard deviation of 2.19. Essentially, Arizona’s quarterback, on average, throws such a high number of short passes, that it is negatively impacting Arizona’s success. Arizona’s passing attempts, passing yards, completion percentage, and long completed throw are all around the league’s average. Arizona’s average amount of attempts per game is 35.58 with a standard deviation of 9.38, as compared to the league’s average of 33.94 with a standard deviation of 8.59. Arizona’s average completion percentage is 64.61 with a standard deviation of 6.51, as compared to the league’s average of 64.127 with a standard deviation of 9.59. Finally, Arizona’s average longest completed pass is 38 yards with a standard deviation of 9.95, as compared to the league’s average of 39.39 with a standard deviation of 8.28. Altogether, Arizona’s quarterback appears to have a relatively high football IQ, and his natural innate abilities appears to be around average in the league, but the decision to throw short passes, regardless of why, is negatively impacting their offense.
Arizona’s running game, though underutilized, is quite effective when called upon. The average number of attempts an essential running back for Arizona takes per game is around 15.0, with a standard deviation of 5.38, compared to the league’s average of 15.9, with a standard deviation of 4.55, so Arizona is around average for the amount of rushes per game they attempt. Arizona’s essential running back’s average rushing yards per game is around 73.4 with a standard deviation of standard deviation of 53.53, as compared to the league average of 69.4 with a standard deviation of 23.3, which means that the team’s reliance on the run game is significantly unpredictable. The essential running back for Arizona’s average yards per carry is 4.50 with a standard deviation of 1.56, as compared to the league’s average of 4.31, with an average of 1.29. The average time Arizona’s essential running backs are behind the line of scrimmage is 2.92, with standard deviation of 0.21, as compared to the league average of 2.82 and a standard deviation of 0.214. The Arizona’s average EFF is 3.86 with a standard deviation of 0.64, as compared to the league’s average EFF of 4.71 with a standard deviation of 1.16. The average number of touchdowns Arizona’s essential running backs score is 0.857 with a standard deviation of 0.83, as compared to the league average of 0.529 with a standard deviation of 0.772
Arizona’s receiving core appears to be of a similar caliber as the Rams’ receiving core. Arizona’s average separation is 3.29, with a standard deviation of 1.08, compared to the league’s average of 2.82, with a standard deviation of 0.91, which means that Arizona’s receivers are relatively better than the average NFL receiver at creating separation. Arizona’s average YAC per reception is 4.74 with a standard deviation of 2.65, as compared to the league’s average of 4.52 with a standard deviation of 3.27, which means that Arizona’s receiving core is essentially average at getting yards after the catch. Even though Arizona’s receiving core appears to be slightly above average, their performance levels are slightly under the expected value, which could possibly be due to quarterback performance. Arizona’s average for yards per game is 54.4, with a standard deviation of 30.7, as compared to the league’s average of 62.2 yards per game with a standard deviation of 44.5, which means that they consistently average less yards per game than the average receiver in the NFL. For the average number of receiving touchdowns per game, Arizona’s collective average  0.257 with a standard deviation of 0.61, as compared to the league average of 0.38 with a standard deviation of 0.529, which means that Arizona’s receiver’s average less than the average NFL receiver, which could be connected to Arizona’s difficulty to sustain and finish long offensive drives. Arizona’s average weekly catch percentage is 67.4, with a standard deviation of 19.59, as compared to the league’s average of 63.14 with a standard deviation of 15.6, which means that Arizona’s receivers do possess an above average catching ability, which could potentially highlight the lack of yards and touchdowns as issues with quarterback performance or play calling. The average target air yards per game for Arizona is 8.4 with a standard deviation of 3.42, as compared to the league’s average of 10.4 with a standard deviation of 3.65, which means that Arizona does average shorter intended passes overall. Though, as previously stated, Kyler Murray was one of the best quarterbacks in the league at completing 40+ yard throws, which means that Arizona’s offense must run a substantial percentage of short intended yard pass plays. When analyzing the perceived threat notion of Arizona’s receivers, the cushion statistic provides insightful information. The average cushion for Arizona’s receivers is 6.1 with a standard deviation of 1.37, as compared to the league’s average of 5.72 with a standard deviation of 1.55, which means that on average, most of Arizona’s opponents view their receiving core to be a slightly above average deep threat level.</p>
<h3 id="strategy-section">Strategy Section:</h3>
<h4 id="arizona-summary-z-and-t-chart">Arizona Summary Z and T chart:</h4>
<figure><img src="https://emr89.github.io/images/FP2.png"/>
</figure>

<h4 id="los-angeles-summary-z-and-t-chart">Los Angeles Summary Z and T chart:</h4>
<figure><img src="https://emr89.github.io/images/FP3.png"/>
</figure>

<h4 id="chi-areas-of-highest-stats">Chi Areas of highest stats:</h4>
<h5 id="rams-defense">Rams Defense:</h5>
<p>Comp = middle of field, 0-10, 10-20-yard area.</p>
<p>TD = right side of the field at 0-10, 10-20 level, and 30+ middle of the field</p>
<p>Int= the middle of the field, all depths</p>
<p>Rush yards ag = left edge (Rams’ directional perspective)</p>
<h5 id="arizona-defense">Arizona Defense:</h5>
<p>Comp = middle of field, 0-10.</p>
<p>TD = right side of the field at 0-10 yards, 10-20, middle – right side. Mostly 0-10.</p>
<p>Int= 10-20 yards middle, right side</p>
<p>Rush yards ag = right edge (Arizona’s directional perspective)</p>
<h5 id="kyler-murray">Kyler Murray:</h5>
<p>Comp = On either side, less completions in middle of field.</p>
<p>TD = middle and right side of the field at 10-20 and 20-30-yard range</p>
<p>Int= middle and right side, 0-10 yards</p>
<h5 id="jared-goff">Jared Goff:</h5>
<p>Comp = the middle and right side of the field at 0-20 yard</p>
<p>TD = come from middle to right side of the field at 10-20 yards</p>
<p>Int= middle and right side of the field at 0-10 yards</p>
<h3 id="game-specific-strategy">Game Specific Strategy:</h3>
<h4 id="synthesis-of-all-data">Synthesis of all data:</h4>
<p>The matchup between the Rams’ offense and Arizona’s defense is vastly one sided. The matchup works in the favor of the Rams’ strengths, offensive versatility, coaching, QB football IQ, receiving core, and offensive line. These strengths enable them to have flexibility when picking a successful strategy. The highlight of Arizona’s defense is their defensive line, which can be game-changing at times. Due to the Rams’ offensive line being slightly above average, and Arizona’s defensive line being slight above average, it would appear to be close to an even match up. Goff’s time to throw, would be his average throughout the year. The weakness of Arizona’s defense is the linebacker core. They allow a high amount of completions, yards, touchdowns, and yards after completion. One major strength of the Rams’ offense is their talented wide receiver core, and their ability to create separation and catch passes. The Rams’ wide receiver core would wreak havoc on the Arizona secondary without any doubt. The best passes would be around the 5-15-yard mark in the middle of the field. Arizona loves to blitz, even though they are relatively inadequate at producing positive results from such blitzes. Though Arizona’s run defense is adequate, it has a major weak spot on their right edge, or off left tackle of the Rams’ offensive line. Coincidentally, the best direction for running backs on the Rams’ offense is off the left tackle. Both edges of Arizona’s defense are relatively weak compared to their inside run tackles and run first linebackers.</p>
<h5 id="offensive-strategy-for-rams">Offensive Strategy for Rams:</h5>
<h6 id="the-theme-of-the-first-quarter-screen-bubble-screens">The theme of the first quarter: SCREEN, BUBBLE SCREENS</h6>
<p>In the first quarter, it is important to capitalize on their trigger-happy blitz tendencies. Bubble screens come after the inside screens, as the initial screen that will be most effective is an inside screen. Due to Arizona’s lack of solid defensive coaching, the defense will blitz and do so with such ignorance that they would not be able to handle or recognize a screen scheme attack plan until after it has been effective at least a couple times, which would lead to at least one to two touchdowns.
In the first quarter, we expose their weakness in the short yardage game, as their blitzing leaves several holes for receivers to catch quick passes, and a lot of open space for screens to overpower them. Arizona’s coaching staff at that point would be preparing to adjust for man coverage, as they would need to account for the running back or receiver that has been getting the ball in open uncovered space.</p>
<h6 id="the-theme-of-the-second-quarter-deep-shots-corners-and-fades">The theme of the second quarter: Deep Shots, Corners, and Fades.</h6>
<p>Though it might seem like an unnecessary idea for the second quarter, it plays a crucial role in breaking down the mentality and half-time game adjustments for Arizona. Arizona’s defensive backs are not skilled in getting interceptions, which reduces the risk of deep shots, so the “price” of taking chances, is quantifiably less. Man coverage would leave our skilled receivers only covered by one person. Our strongest core on the team (our wide receivers) versus their weakest core in single matchups (their linebackers and defensive backs), would be exactly what we could capitalize on. That would be primetime for Cooper Kupp and his incredible ability to create separation. In this situation, a deep shot would be at its highest probability of success and would be effective in further beating down Arizona’s defense. If the offense can capitalize five times in the second quarter on a pass worth 25+ yard completions, it would lead to at least one to two quickly scored touchdowns. Due to Arizona’s coaching factors and offense, they would be greatly behind at this point in the game. With Arizona being a young team, a gap of 21+ points would create discouragements that Arizona would find incredibly difficult to overcome.
The main goal of the second quarter is to stretch them deep as well, so that they leave their linebackers in an inside run first formation from our first quarter tactics, and their DBs will give more of a cushion from our second quarter strategy.</p>
<h6 id="the-theme-of-the-third-quarter-posts-fleaflickers-counters-sweeps-and-draws">The theme of the Third Quarter: Posts, Fleaflickers, Counters, Sweeps, and Draws.</h6>
<p>Arizona’s true weakness is their middle level personnel. Their inside linebackers give up an overwhelming amount of completions, yards, touchdowns, and YAC in that area of the field. They also have a high rate of missed tackles in that area of the field. After our first half performance, they would switch to zone coverage for two reasons. First, they would realize their skill positions are outmatched one on one. Second, their offense is most effective in the third and fourth quarters, so their game plan would be to prevent any “big” or quick scoring plays by going zone and covering deep. For the Rams, the lack of a blitz and zone coverage would provide Goff with a more comfortable pocket. The most effective place of attack in zone coverage against Arizona is in the middle of the field, around 7-15 yards past the line of scrimmage. This combination sets up the Post for some breathing room, which is a good chunk of yards every time. Additionally, this extra breathing room for receivers would set up ideal conditions for a special flea flicker once the post routes have gotten predictable. For run plays, now that Arizona is relying on zone, misdirection with counters, spreading with sweeps, and reactive decision making with draws, would expose the vulnerable Arizona defensive front. The Rams’ offense has a plethora of speedy skill players, which we can utilize to tire out Arizona’s defensive front. As done earlier in the season, using an in-motion wide receiver as a running back on a sweep would be highly effective at this point in the game, and would open up several possibilities for the fourth quarter, as a tired defensive front allows for more time to set up any type of play. Zone also allows for more schematic match ups to occur. Calling draw plays would enable Goff to use his high football IQ to decide the best matchup at that moment would be effective against their defensive front at this point in the game. Finally, running counters would add a level of deception strong enough to capitalize on Arizona’s poorly coached and young defense; it would create a sense of hesitation for several players in Arizona’s defense. It would be highly unlikely that Arizona’s coaching staff would have prepared them for circumstances so specific. Therefore, the lack of communication and preparation would clog up Arizona’s defense from the inside, as any team that is inadequately coached, will struggle to adapt to the complex in game issues as a cohesive unit. The interaction between the beneficial impacts of those various plays will confuse and tire out Arizona’s defense and limit the time that Arizona’s Offense is on the field.</p>
<h6 id="theme-of-the-fourth-quarter-time-management-or-time-to-finish-them">Theme of the Fourth Quarter: Time Management or Time to Finish Them</h6>
<p>The game plan thus far has led to one concept that has endless flexibility and possibilities: control. Depending on the score and circumstances, the theme of the fourth quarter will either be Time Management or “Time to Finish Them”.</p>
<h6 id="time-management">Time Management:</h6>
<p>If the Rams have a commanding lead of 14+, then the time management path is ideal. It is essentially the widely known and accepted time management plan that NFL coaches use. Maximize the length of your offensive drives and always finish plays in bounds, do not let up big yardage plays on defense, prevent Arizona from getting out of bounds, etc. Due to our strategy off stretching their defense thin, wearing them out, and confusing them, time management will become more manageable, offensive drives will become more sustainable. The only variation from the widely accepted time management notion is the of “padded boundary passes” that I have designed.
Essentially, you use formations such as “deuces”, where you can quickly have two receivers near the boundaries on each side as quickly as possible, and you target the areas of the field that they wouldn’t expect, near the boundaries, but you set up a “fail safe” so that they are not pushed out of bounds. The outside guy in the Deuce formation should be “tight end sized” and would be the “pad” in the process , and the inside guy should be “slot/slim sized” with quickness and great catching ability, and he would be the target.
The execution of the “padded boundary pass” is the following: The target would actually run a route that is actually designed to take the receiver out of bounds, as the defense is not expecting those pass routes when you are managing the clock. The “pad” would run a route directly to where the target is GOING to be one second after he catches the pass and would keep inside yard width from the boundary. The “pad” would act as a precautionary measure to ensure the target is not pushed out of bounds. If the backs are not in an arm’s length distance to the target when the target catches the pass, then the target can just take a knee, or advanced the pass to get the first down to continue the drive. If the backs are in an arm’s length from the target when he catches the pass and there is a danger of the target being pushed out of bounds, the “pad” would use his body legally to prevent the target from being pushed out.
Besides the “padded boundary pass”, time management would proceed as expected. Additionally, using power backs, two blocking tight tends, and lead blockers would maximize our average yards per carry. This type of formation should only be used on some plays and would be better if they were disguised as another formation, and then executed like a counter play. These conditions would help all the various pieces of the power I formation come together unexpectedly, so that the defense could only identity the power formation once the play was almost entirely executed.</p>
<h6 id="time-to-finish-the-job">Time to Finish The Job:</h6>
<p>If circumstances have not gone as expected at this point in the game, and the score is close, or we are even behind, then we could use the conditions we set up to execute big plays by manipulating the conditions we have controlled throughout the game. Our third quarter strategy of wearing down the defense would be successful if we stretched their defense thin and made them pursue our ball-handler over long distances. Due to the matchup between our Offensive Line and their Defensive Line, Goff’s time to throw would most likely be at its highest of the game thus far. Depending on the issues with the earlier game plan, adjustments would be made around the direction of the play calling.</p>
<h4 id="adjustments">Adjustments:</h4>
<h5 id="if-the-strategy-from-quarter-one-was-lacking-and-arizona-defended-the-screen-well">If the strategy from quarter one was lacking, and Arizona defended the screen well:</h5>
<ol>
<li>Arizona did not blitz as much as they usually do</li>
<li>Arizona’s blitz overpowered our offensive line and did not give Goff enough time to set up pass for the screen.</li>
<li>Arizona was in man defense and there was a defender in the vicinity of the running back/ receiver catching the screen</li>
</ol>
<h5 id="answers">Answers:</h5>
<ol>
<li>The strategy from quarter three would be effective in working against their zone defense, and the strategy from quarter two would be effective against their man defense.</li>
<li>Utilizing tight ends to give the defensive rushers a chip to delay their speed, or an extra running back in the backfield to prevent the rush from appearing too quickly</li>
<li>The strategy from quarter two would expose their weakness in man defense with the single DB and wide receiver matchups, which would either be a better strategy if they cannot stop that strategy, or if they adjust to zone defense to stop the one on one matchups, then zone would provide a better environment to run the screen plays.</li>
</ol>
<h5 id="if-the-strategy-from-quarter-two-did-not-work">If the strategy from quarter two did not work:</h5>
<ol>
<li>Our receivers are continuously losing the one on one matchups.</li>
<li>Our Quarterback cannot accurately deliver the ball deeply down field.</li>
<li>Our Quarterback does not have enough time to throw the ball.</li>
<li>Arizona’s defense is only in zone defense.</li>
</ol>
<h5 id="answers-1">Answers:</h5>
<ol>
<li>This outcome is statistically quite unlikely, BUT one major factor that impacts this is the amount of cushion their backs give our receivers. Our receiver’s ability to create separation is unmatched and we will capitalize on that. If the receivers are losing deep one on one routes, it is probably due to the high yardage cushion the backs are leaving, therefore, short passes will be relatively uncontested. The strategy from quarter one of quarter three might be effective at in this situation until the backs start to consistently leave less cushion.</li>
<li>Medium pass routes are probably most desirable, as Arizona’s backs are relatively incompetent. Posts, drags, corners, hitch and goes, wheel routes, and flea flicker style variations would all be beneficial in this situation if they are in man. If they are in zone, the strategy from quarter three would be most effective.</li>
<li>Utilizing tight ends to give the defensive rushers a chip to delay their speed, or an extra running back in the backfield to prevent the rush from appearing too quickly.</li>
<li>Use strategy from quarter three.</li>
</ol>
<h5 id="if-strategy-from-quarter-three-did-not-work">If strategy from quarter three did not work:</h5>
<ol>
<li>Arizona has remained in man defense</li>
<li>Arizona has remained in man defense and they continuously winning the one on one matchups</li>
<li>Our run block is not effective enough</li>
<li>Our execution of reactive plays like draws is lacking.</li>
</ol>
<h5 id="answers-2">Answers:</h5>
<ol>
<li>Continue to use the strategy from the second quarter if it is effective.</li>
<li>Adjust the strategy from quarter two to create favorable one on one match ups by using trick plays, misdirection, and scramble rules. Otherwise, try misdirection with power formations.</li>
<li>Use strategy from the first quarter if Arizona is blitzing again a lot, switch to short passing game in flats, or utilize check downs.</li>
<li>Stick to planned pass routes and planned run routes. Use power formations if in need improved blocking.</li>
</ol>
<p>Follow the previous option list for strategy in fourth quarter comeback or finisher. Also create additional adjustments during halftime, which cannot be done ahead of time in a preplanned strategy such as this.</p>
<h4 id="defensive-matchup-through-previous-analysis-and-observation">Defensive Matchup: (Through previous analysis and observation)</h4>
<p>When creating a defensive strategy, creating a quarter by quarter game plan is not ideal, because defense is almost entirely reactionary. The preplanned preparation in defensive strategies is understanding your opponent’s offensive tendencies and abilities.</p>
<h4 id="understanding-arizonas-tendencies">Understanding Arizona’s Tendencies:</h4>
<p>The matchup between the Rams’ defense and Arizona’s offense is more balanced than its counterparts, and both have blatant weaknesses as well as strengths. Arizona’s offense prides itself in its versatility, and its partial deception of its identity. On the surface, Arizona’s offense appears to be a pass centralized system that is led by Kyler Murray’s elusive scrambling and his strong arm. But, in reality, Arizona’s offense is rooted in its running versatility and durability, which affords them the ability to successfully execute their centralized pass system. Surprisingly, these impressive characteristics are only possible due to the “Yin and Yang” relationship of the system in their offense.
For example, Arizona’s passing game greatly improved when Arizona had acquired Kenyan Drake…a running back. At the time of the trade, Kenyan Drake was an overlooked and underappreciated running back for the rebuilding Miami Dolphins. Drake’s rushing average with the Dolphins was substantially worse than what it was after he was traded, mostly because Miami’s offense was predictable and weak in all other aspects. Even in Miami, Drake showed consistent durability, which is what Arizona’s run offense needed. Predictability killed the Miami Dolphins during the 2019 season. As the opposition’s defenders knew Drake was taking a handoff before he had even touched the ball. Unpredictability boosted Arizona throughout their season, as Drake’s “breakaway” designed play is saved for occasional plays during the game.
Arizona has a relatively low number of rush attempts per game rate as compared to the rest of the league, but their rushing yards per game and rushing average per carry is relatively high. Could this be due to the sheer skill of the running backs alone? Possibly, but there is a more centric reason. The success of Arizona’s rushing game is rooted in the timing of the play calling. Just like Yin and Yang create and ever repeating cycle, Arizona’s offense flourishes when it consistently executes a repeating cycle that determines the balances between pass and rush. The cycles start with Arizona’s short passing game and running game at a near balance, primarily at the short to medium length interval passing at the beginning of the game and inside runs. The pass plays will prove to be more effective initially. Since Arizona’s offense is young, led by a young quarterback, it takes the offense time to shift into place to operate effectively. After two drives or so, the next couple of Arizona’s drives have a 2:1 pass to run ratio but sputtering after one or two first downs. The key is the use of the swing passes and check downs to free up the lanes for the running back. After a drive or two, the constant passing, especially on crucial downs, pushes the defense to a zone defense, especially since Murray has set up a double passing threat at this point. Murray can sling a medium pass to Fitzgerald for a moderate gain, or hit his running back leaving the backfield if there are no other options, and if his receivers are well coached and good at scramble rules, Murray and Arizona’s offense will have more time to develop a play. Stretching the defense out sets up ideal conditions for a durable running back like Kenyan Drake to hit the poorly defended lane with strong bursts of power and speed. This usually occurs in the second to third quarter. The ball is generally handed to Drake on a drive run, usually between their left tackle and guard, and due to zone coverage, Drake usually finds enough room to gash the defense for a few 10+ yard plays. Finally, when defenses start to try and plug these running lanes, most defenses adjust to man at this point, which is when Arizona’s passing game goes for a deep shot. Arizona’s receivers are generally fast, so an unsuspecting defense will have trouble adjusting on the fly. Arizona tends to like their one on one matchups between their receivers and the opponent’s defensive backs. When the defense switches to man defense, Arizona will take a few sporadic shots down field, especially after a long run from the running backs, as the play action pass creates enough hesitation for Arizona’s receivers to gain the edge against any team. Even the San Francisco 49ers’ defense became vulnerable deep-down field when they switched to man defense.</p>
<h4 id="understand-arizonas-abilities">Understand Arizona’s abilities:</h4>
<p>Arizona’s offense relies heavily on balance of run and pass, so receivers, running backs, and their quarterback are extremely effective in some situations, but are blatantly sub-par in others. The main component of Arizona’s offense that is almost always a hinderance is their offensive line, which is better at run blocking than then it is at pass blocking. A below average offensive line would usually greatly hinder the performance of the entire offense, except the strengths of all the skill positions on the offense were specific to the lack of a strong offensive line. When it comes to the passing game, Arizona is trying to emulate our shared division rival’s offensive style.
The Seattle Seahawks and Russel Wilson are the blueprint for a high performing offense with a mediocre offensive line. The style of offensive is a reaction-based decision system, almost like a decision tree. A versatile quarterback with excellent scrambling ability, an above average arm, and a creative football IQ is needed at the QB position. Equally important to this style of offense is precisely defined scrambling rules for receivers and strong connections between receivers and quarterbacks. The receivers don’t have to be the best receivers in the league, they just need to be able to create momentary separation, to which the Quarterback needs to have a high football IQ to be able to track and predict  instantaneously to make the best throw.
First, one of the strengths of Arizona’s system is Kyler Murray’s ability to scramble and maneuver in the pocket gracefully and still get the ball on target down field. Kyler’s elusive presence in the pocket minimizes the offensive line’s inability to pass block effectively. Another strength Arizona has is an experienced veteran wide receiver, one of the best, Larry Fitzgerald. He is constantly a reliable target for Kyler as a low risk, high reward option. Undoubtedly, Fitzgerald created on solid connection with Kyler and is easily able to adjust and cover for Kyler’s lack of experience, which has eased Kyler’s transition into the NFL.
One of the glaring weaknesses of this system is Kyler’s lack of experience in reading defenses and adjusting to unknown formations. The 2019 season is Kyler’s rookie season, though he has performed better than expected across the league, he still lacks the innate ability to read defenses in a second’s notice and adjust instantaneously. Factors such as uncommon formations, intricately connected formations, and unusual blitzing patterns, expose the rookie’s inexperience. His composure in the pocket melts away at the sight of unfamiliar schemes. Another weakness connected to his composure, is Kyler’s inability to stand in the pocket unfazed by peripheral pressure to deliver an accurate ball. If the defensive rush has penetrated the offensive line in any substantial manner, Kyler instinctively scrambles outside of the pocket, which help him evade the perceived threat, but increases his vulnerability to the unnoticed threats behind his periphery. Another weakness of this system is Arizona’s lack of consistent receivers, apart from Fitzgerald. In this system, its key to have several consistently decent receivers, so the defense cannot just double cover the only credibly threat. The importance of the scramble passing system is the slight edge that the receivers would have in the one versus one matchup. There needs to be a handful of competent receivers versus one excellent receiver and several unimpressive receivers. In several instances, the overall receiving core for Arizona was greatly outmatched by the defensive backs of their opponent, mainly because Fitzgerald was the only receiver that could win the one versus ones, so he was the only receiver that required double coverage.
Even though Arizona’s offensive play calling balance between pass and run follows the cycle of yin and yang stated above, the order of the play calling is quite more predictable. When the offense is trying to get in sync during the first and second quarter, first down plays are usually run if it is near midfield, or pass if it is near either end of the field, and third downs are usually pass if its long yardage or middle of the field, but will occasionally be a “trick” run play if it is near the RedZone. During the third quarter, the rush and pass play calling is determined by the general defensive formation for the most part, except for second down which is usually a run with Drake. In the fourth quarter, the play selection depends more on the score. If they are winning, which does not happen usually, they call a lot of short passes and outside runs. If they are losing, they start the fourth quarter trying to use some form of trick run play, so that they maximize the probability of success for their deep shots, which enables their offense some form of flexibility. If that is not working, then the offense likes to use rollout passes and scramble techniques to hope that a deep connection downfield, or in open field, can be made.
The emphasis of Arizona’s weakness is in their offensive line’s passing blocking ability, and Kyler Murray’s inexperience. The most effective game plan would be centered around various blitzing schemes, especially from the outside, containing Murray is key.<br>
Overall, Arizona’s offense is a well formulated and balanced system designed to maximize the efficiency of both run and pass plays, but due to their young and under coached roster, and their abysmal offensive line,  there are numerous opportunities to break down the efficiency of that system and capitalize on their mistakes.</p>
<h4 id="rams-defensive-abilities">Rams’ Defensive abilities:</h4>
<p>The Rams’ defense throughout the 2019 season has been a group of individuals with immense promise, explosive flares of greatness, but general inconsistencies. The high moments are grand, such as the victory against the Saints or the Seahawks, but the lows are bewildering, such as the loss against the Buccaneers or the Ravens. Though there are several factors that the defense does consistently well, and all those factors are related to pass rushing. The defensive line is bolstered just by the presence of the Aaron Donald. The defense’s sack rate, sack rate yards lost, and pressure amount is quite strong and consistent.  The defense can blitz and pressure the quarterback quite adequately. The wild inconsistencies come from the linebackers, who statistically are average over the culmination of the season, but due to the high variation of game performance, shown to have performed at various levels at different points in the season. Signing Jalen Ramsey has appeared to help the general average performance of all defensive backs, but not by enough to explain why the defensive back’s performance varied so dramatically. A major area for improvement on this defense is the ability to create turnovers. Though the interception rate was around average for the league, the forcing fumble rate and fumble recovery rate are far below average. Any additional unit increases in fumble recoveries can have the most profound impact on the direction of the game, especially considering the high caliber passing offense that the Rams have.</p>
<h4 id="how-do-the-rams-defeat-this-system">How do the Rams’ defeat this system?</h4>
<p>Many of the weaknesses of this offensive system have similar triggers depending on the style of defense preferred. If the matchups between Arizona’s receiving core and our defensive backs are heavily in our favor, then using a man-based defense would be a viable and efficient solution to their system.
If the matchups between our defensive backs and their receiving core are too close for comfort, or even favorable in their direction, then the use of systematic blitzing and unrecognizable defensive formations that serve as a façade are ideal. This style of reaction based offense relies heavily on the offense being able to interpret the defense’s scheme and tendencies to pinpoint play calls and areas of the field that the defense is not expecting or that the defense is not capable of defending. This style is heavily reliant on communication and mutual understanding of situational rules for execution. Creating miscommunication and hesitation in this system is what is most effective in dismantling the effectiveness of this style of offense. The combination of Kyler’s inexperience, the offensive line’s ineptitude, and the receiver’s inconsistency will result in a vulnerability to unfamiliar situational circumstances. The hesitation that Kyler will experience, from attempting to read the unrecognizable defense, will give the defensive line, specifically Aaron Donald, valuable extra time needed to break into the backfield. The unfamiliar defensive formations will test the connection between receiver and quarterback, such that their instinctual tendencies would need to be identical to be able to adjust appropriately to the situation. Systematic blitzing techniques would either create more viable opportunities to sack Kyler or would add another level of hesitation as of what to expect for various forms of pressure in the pocket.</p>
<h4 id="regardless-of-runpass-focus-plan">Regardless of Run/Pass focus plan:</h4>
<p>Though man coverage against Arizona’s offense can lead to vulnerability if not called at the right time, man defense combined with blitzing stunts would be the most effective tactic overall against Arizona’s offense when they are at their most potent.
In the first quarter, the first couple of drives should be zone with blitzing and “falsified” formation looks. The falsified formation looks are to confuse Murray and his receivers just long enough that the blitz can get to Murray. Arizona’s right tackle and guard are the weakest links. Additionally, Murray struggles with rolling out to the left, so the contain guy should come off their right tackle, or our left defensive end. The combination of the hesitance that Murray will have to read the defense to put the ball in the correct spot, as well as the unpredictable directions of pressure, will create enough pressure to sack Murray early and often. If the Rams’ offense can put up 14 points in the first quarter or 21 points in the first half while containing Arizona to 3 or less points, Arizona’s second half plan will be become overly predictable. It will likely result in 1 run and 2 passes, one of those passes being play action, and one pass being atleast 20+ yard attempts.
Second quarter and early third quarter should be focused on man defense. Especially due to the mismatch in the matchup between our defensive backs and their wide receivers, man defense would be the best route, with Ramsey covering Fitzgerald. This tactic will essentially help us glide with them until they start to commit to either the pass or the run, while forcing them to gamble on either pass or run because our defense wouldn’t have committed to stop the deep passing or clogging the run. Additionally, while in man defense, the defensive backs should give a substantial amount of cushion room, around 7-8 yards, so that they will have to march down the field to score. Additionally, it appears that the probability that the Rams come away with an interception is higher than the probability that the defensive backs let up a deep pass touchdown. Focusing on man defense at this point of the game seems logically effective given their tendencies and probability of success.
Late third and fourth quarter should be focused on zone or nickel formation, with an occasional blitz, but several blitz showings pre-snap. At this point in the game, Murray will be pressured to make a deep shot down field and showing blitz or shifting formations might pressure him enough to make a mistake, or delay him enough to get sacked or tackled barely beyond the line of scrimmage.</p>
<ul class="pa0">
  
   <li class="list di">
     <a href="https://emr89.github.io/tags/scene/" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">Scene</a>
   </li>
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://emr89.github.io/" >
    &copy;  Eric Matthew Rupinski  2024 
  </a>
    <div>
<div class="ananke-socials">
  
</div>
</div>
  </div>
</footer>

  </body>
</html>
